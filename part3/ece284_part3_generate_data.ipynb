{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OiOGdaYAM49",
        "outputId": "98880990-e278-49a4-f345-8b1154dcde6f"
      },
      "id": "8OiOGdaYAM49",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Add the directory containing 'models.py' to Python's path\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/') # Assuming 'models.py' is directly in MyDrive\n",
        "\n",
        "# 3. Import the module\n",
        "import models\n",
        "from models import *"
      ],
      "metadata": {
        "id": "8CsHuxN-ANl2"
      },
      "id": "8CsHuxN-ANl2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea58bec-9630-4707-b844-20566b213ebb",
      "metadata": {
        "id": "fea58bec-9630-4707-b844-20566b213ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b7e248-0b91-40b4-c252-7dc04db75f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model...\n",
            "VGG_quant(\n",
            "  (features): Sequential(\n",
            "    (0): QuantConv2d(\n",
            "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): QuantConv2d(\n",
            "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): QuantConv2d(\n",
            "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): QuantConv2d(\n",
            "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): QuantConv2d(\n",
            "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): QuantConv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): QuantConv2d(\n",
            "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): QuantConv2d(\n",
            "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (26): ReLU(inplace=True)\n",
            "    (27): QuantConv2d(\n",
            "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (28): ReLU(inplace=True)\n",
            "    (29): QuantConv2d(\n",
            "      8, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (30): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (31): ReLU(inplace=True)\n",
            "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (33): QuantConv2d(\n",
            "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): QuantConv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (38): ReLU(inplace=True)\n",
            "    (39): QuantConv2d(\n",
            "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "      (weight_quant): weight_quantize_fn()\n",
            "    )\n",
            "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (41): ReLU(inplace=True)\n",
            "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  )\n",
            "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from models import *\n",
        "\n",
        "\n",
        "global best_prec\n",
        "use_gpu = torch.cuda.is_available()\n",
        "print('=> Building model...')\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "model_name = \"VGG16_quant_8x8\"\n",
        "model = VGG16_quant_8x8()\n",
        "\n",
        "print(model)\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        normalize,\n",
        "    ]))\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
        "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
        "\n",
        "def train(trainloader, model, criterion, optimizer, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(trainloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        input, target = input.cuda(), target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec = accuracy(output, target)[0]\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(prec.item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
        "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
        "                   data_time=data_time, loss=losses, top1=top1))\n",
        "\n",
        "\n",
        "\n",
        "def validate(val_loader, model, criterion ):\n",
        "    batch_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "\n",
        "            input, target = input.cuda(), target.cuda()\n",
        "\n",
        "            # compute output\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            # measure accuracy and record loss\n",
        "            prec = accuracy(output, target)[0]\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(prec.item(), input.size(0))\n",
        "\n",
        "            # measure elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
        "                print('Test: [{0}/{1}]\\t'\n",
        "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
        "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
        "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
        "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
        "                   top1=top1))\n",
        "\n",
        "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
        "    return top1.avg\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, fdir):\n",
        "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
        "    torch.save(state, filepath)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
        "\n",
        "\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
        "    adjust_list = [100, 150, 180]\n",
        "    if epoch in adjust_list:\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = param_group['lr'] * 0.1\n",
        "\n",
        "#model = nn.DataParallel(model).cuda()\n",
        "#all_params = checkpoint['state_dict']\n",
        "#model.load_state_dict(all_params, strict=False)\n",
        "#criterion = nn.CrossEntropyLoss().cuda()\n",
        "#validate(testloader, model, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ffd7aa173a3ff",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-15T21:26:30.805723Z",
          "start_time": "2025-11-15T21:26:30.796471Z"
        },
        "id": "20ffd7aa173a3ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7ad9592-14a3-4836-8524-b96c590f9103"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantConv2d(\n",
              "  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
              "  (weight_quant): weight_quantize_fn()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "\n",
        "model.features[0] ## Modified layer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # This cell is from the website\n",
        "\n",
        "# lr = 1e-2\n",
        "\n",
        "\n",
        "\n",
        "# weight_decay = 1e-4\n",
        "# epochs = 200\n",
        "# best_prec = 0\n",
        "\n",
        "# model = model.cuda()\n",
        "# criterion = nn.CrossEntropyLoss().cuda()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.94, weight_decay=weight_decay) #changed momentum and learning rate\n",
        "# # weight decay: for regularization to prevent overfitting\n"
      ],
      "metadata": {
        "id": "WjR7JiQQBJn9"
      },
      "id": "WjR7JiQQBJn9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# if not os.path.exists('result'):\n",
        "#     os.makedirs('result')\n",
        "\n",
        "# fdir = 'result/'+str(model_name)\n",
        "\n",
        "# if not os.path.exists(fdir):\n",
        "#     os.makedirs(fdir)\n",
        "\n"
      ],
      "metadata": {
        "id": "TQBtmr9vCgqH"
      },
      "id": "TQBtmr9vCgqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for epoch in range(0, epochs):\n",
        "#     adjust_learning_rate(optimizer, epoch)\n",
        "\n",
        "#     train(trainloader, model, criterion, optimizer, epoch)\n",
        "\n",
        "#     # evaluate on test set\n",
        "#     print(\"Validation starts\")\n",
        "#     prec = validate(testloader, model, criterion)\n",
        "\n",
        "#     # remember best precision and save checkpoint\n",
        "#     is_best = prec > best_prec\n",
        "#     best_prec = max(prec,best_prec)\n",
        "#     print('best acc: {:1f}'.format(best_prec))\n",
        "#     if is_best:\n",
        "#       save_checkpoint({\n",
        "#         'epoch': epoch + 1,\n",
        "#         'state_dict': model.state_dict(),\n",
        "#         'best_prec': best_prec,\n",
        "#         'optimizer': optimizer.state_dict(),\n",
        "#     }, is_best, fdir)\n",
        "\n",
        "#     if prec > 90: break\n"
      ],
      "metadata": {
        "id": "ed6RlI-JChe7"
      },
      "id": "ed6RlI-JChe7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r  /content/result/VGG16_quant_8x8 /content/drive/MyDrive/result\n"
      ],
      "metadata": {
        "id": "36hThpcGCt8_"
      },
      "id": "36hThpcGCt8_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "entertaining-queensland",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-22T01:31:53.437014Z",
          "start_time": "2025-11-22T01:31:43.289564Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "entertaining-queensland",
        "outputId": "a712a91f-b77c-4f07-c648-abaf6b592833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Accuracy: 3159/10000 (32%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "PATH = '/content/drive/MyDrive/result/VGG16_quant_8x8/model_best.pth.tar'\n",
        "checkpoint = torch.load(PATH)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, target in testloader:\n",
        "        data, target = data.to(device), target.to(device) # loading to GPU\n",
        "        output = model(data)\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(testloader.dataset)\n",
        "\n",
        "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, len(testloader.dataset),\n",
        "        100. * correct / len(testloader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceramic-nigeria",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-22T01:42:27.948581Z",
          "start_time": "2025-11-22T01:42:20.360074Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceramic-nigeria",
        "outputId": "9e123327-7195-46e2-ceee-f143edc89e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 1\n",
            "7 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 2\n",
            "12 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 3\n",
            "16 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 4\n",
            "21 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 5\n",
            "25 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 6\n",
            "29 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 7\n",
            "34 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 8\n",
            "38 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 9\n",
            "41 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  8, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 10\n",
            "46 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 11\n",
            "50 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 12\n",
            "54 -th layer prehooked \n",
            " QuantConv2d(\n",
            "  512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "  (weight_quant): weight_quantize_fn()\n",
            ") 13\n"
          ]
        }
      ],
      "source": [
        "class SaveOutput:\n",
        "    def __init__(self):\n",
        "        self.outputs = []\n",
        "    def __call__(self, module, module_in):\n",
        "        self.outputs.append(module_in)\n",
        "    def clear(self):\n",
        "        self.outputs = []\n",
        "\n",
        "######### Save inputs from selected layer ##########\n",
        "save_output = SaveOutput()\n",
        "i = 0\n",
        "count = 0\n",
        "for layer in model.modules():\n",
        "    i = i+1\n",
        "    if isinstance(layer, QuantConv2d):\n",
        "        count += 1\n",
        "        print(i,\"-th layer prehooked \\n\", layer, count) #'count' here is just for me to check the index of save_output.outputs[][0]\n",
        "        layer.register_forward_pre_hook(save_output)\n",
        "####################################################\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.to(device)\n",
        "images_abs = torch.abs(images) # taking absolute value of image input since our feature map activations are assumed to be unsigned positive values.\n",
        "out = model(images_abs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9c5pvnYLr06",
        "outputId": "467faabe-359e-474d-f32b-d78aa0752ad8"
      },
      "id": "k9c5pvnYLr06",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 3, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "spoken-worst",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-22T01:44:21.962568Z",
          "start_time": "2025-11-22T01:44:21.947066Z"
        },
        "id": "spoken-worst"
      },
      "outputs": [],
      "source": [
        "weight_q = model.features[0].weight_q\n",
        "w_alpha = model.features[0].weight_quant.wgt_alpha\n",
        "w_bit = 4\n",
        "\n",
        "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
        "#print(weight_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "interior-oxygen",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-22T01:44:22.995590Z",
          "start_time": "2025-11-22T01:44:22.979962Z"
        },
        "id": "interior-oxygen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4343f07f-f38d-4cfe-b66c-8801ee9899d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(True, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "act = images_abs\n",
        "act_alpha  = model.features[0].act_alpha\n",
        "act_bit = 4\n",
        "act_quant_fn = act_quantization(act_bit)\n",
        "\n",
        "act_q = act_quant_fn(act, act_alpha)\n",
        "\n",
        "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
        "print(torch.all(act_int >= 0)) ## all are positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ranging-porter",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-22T01:44:24.548267Z",
          "start_time": "2025-11-22T01:44:24.532590Z"
        },
        "id": "ranging-porter"
      },
      "outputs": [],
      "source": [
        "conv_int = torch.nn.Conv2d(in_channels = 3, out_channels=64, kernel_size = 3, padding=1)\n",
        "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
        "relu = torch.nn.ReLU()\n",
        "conv_int.bias = model.features[0].bias\n",
        "output_int = conv_int(act_int) # The most important thing\n",
        "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
        "output_recovered_relu = relu(output_recovered)\n",
        "#print(output_recovered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "157dffd8",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-11-22T01:45:40.953582Z",
          "start_time": "2025-11-22T01:45:40.930278Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "157dffd8",
        "outputId": "212690dd-9d3c-465d-bf76-3eb2c9c33aa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 64, 32, 32])\n",
            "tensor(2.7382, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(save_output.outputs[1][0].shape)\n",
        "difference = abs(save_output.outputs[1][0] - output_recovered_relu )\n",
        "print(difference.mean())  ## It should be small, e.g.,2.3 in my trainned model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. Conv hyperparameters – EDIT THESE TO MATCH YOUR LAYER\n",
        "# --------------------------------------------------\n",
        "stride = 1        # or (1, 1)\n",
        "padding = 1       # use 0 if you had no padding\n",
        "dilation = 1\n",
        "groups = 1\n",
        "\n",
        "use_bias = False  # set True and define bias_int if your conv has bias\n",
        "bias_int = None   # e.g. torch.randint(..., size=(64,), dtype=torch.int16)\n",
        "\n",
        "# If you do integer scaling (e.g., >> shift_bits after accumulation)\n",
        "apply_shift = False\n",
        "shift_bits = 3    # example: right shift by 3\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. Basic sanity prints\n",
        "# --------------------------------------------------\n",
        "print(\"act_int.shape    :\", act_int.shape)     # [128, 3, 32, 32]\n",
        "print(\"weight_int.shape :\", weight_int.shape)  # [64, 3, 3, 3]\n",
        "print(\"output_int.shape :\", output_int.shape)  # [128, 64, 32, 32]\n",
        "\n",
        "batch = 5\n",
        "out_c = 1\n",
        "h = 0\n",
        "w = 0\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 3. Float conv2d reference using act_int & weight_int\n",
        "# --------------------------------------------------\n",
        "act_f = act_int.to(torch.float32)\n",
        "weight_f = weight_int.to(torch.float32)\n",
        "\n",
        "bias_f = None\n",
        "if use_bias and bias_int is not None:\n",
        "    bias_f = bias_int.to(torch.float32)\n",
        "\n",
        "out_f = F.conv2d(\n",
        "    act_f, weight_f,\n",
        "    bias=bias_f,\n",
        "    stride=stride,\n",
        "    padding=padding,\n",
        "    dilation=dilation,\n",
        "    groups=groups,\n",
        ")\n",
        "\n",
        "print(\"F.conv2d reference (float):\", out_f[batch, out_c, h, w].item())\n",
        "print(\"Stored output_int          :\", output_int[batch, out_c, h, w].item())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 4. Manual integer convolution using act_int & weight_int\n",
        "# --------------------------------------------------\n",
        "# We need to mimic the same padding as conv2d.\n",
        "# F.pad pads in the order (left, right, top, bottom).\n",
        "if isinstance(padding, int):\n",
        "    pad_left = pad_right = pad_top = pad_bottom = padding\n",
        "else:\n",
        "    # if you used tuple padding, adjust this section\n",
        "    pad_left = pad_right = padding[1] if isinstance(padding, tuple) else padding\n",
        "    pad_top  = pad_bottom = padding[0] if isinstance(padding, tuple) else padding\n",
        "\n",
        "act_padded = F.pad(act_int, (pad_left, pad_right, pad_top, pad_bottom))\n",
        "\n",
        "# Kernel size\n",
        "_, in_channels, kH, kW = weight_int.shape\n",
        "\n",
        "# For stride=1, dilation=1, the input top-left index for output (h, w) is:\n",
        "h_in = h * stride\n",
        "w_in = w * stride\n",
        "\n",
        "# Extract 3x3 (or kH x kW) patch from padded input\n",
        "patch_int = act_padded[batch, :, h_in:h_in + kH, w_in:w_in + kW]   # [Cin, kH, kW]\n",
        "kernel_int = weight_int[out_c]                                    # [Cin, kH, kW]\n",
        "\n",
        "# Integer accumulation in int32 to avoid overflow\n",
        "acc_int32 = (patch_int.to(torch.int32) * kernel_int.to(torch.int32)).sum()\n",
        "\n",
        "if use_bias and bias_int is not None:\n",
        "    acc_int32 = acc_int32 + int(bias_int[out_c].item())\n",
        "\n",
        "print(\"Manual integer accumulator :\", acc_int32.item())\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 5. Optional: apply integer scaling / shifting and clamp to int16\n",
        "# --------------------------------------------------\n",
        "if apply_shift:\n",
        "    # arithmetic right shift for signed values\n",
        "    acc_shifted = acc_int32 >> shift_bits\n",
        "else:\n",
        "    acc_shifted = acc_int32\n",
        "\n",
        "# Clamp to int16 range\n",
        "acc_int16 = torch.clamp(acc_shifted, -32768, 32767).to(torch.int16)\n",
        "\n",
        "print(\"Manual quantized int16     :\", acc_int16.item())\n",
        "print(\"Stored output_int          :\", output_int[batch, out_c, h, w].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD1ggcQ0QrHS",
        "outputId": "298cfde6-dfc4-4fb3-b3ee-a3be53f928cb"
      },
      "id": "pD1ggcQ0QrHS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "act_int.shape    : torch.Size([128, 3, 32, 32])\n",
            "weight_int.shape : torch.Size([64, 3, 3, 3])\n",
            "output_int.shape : torch.Size([128, 64, 32, 32])\n",
            "F.conv2d reference (float): 28.0\n",
            "Stored output_int          : 28.0\n",
            "Manual integer accumulator : 28\n",
            "Manual quantized int16     : 28\n",
            "Stored output_int          : 28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 5\n",
        "X = act_padded[batch,:,:,:]  # pick only one input C_in, ni, nj\n",
        "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # out_ch = 64, in_ch = 3, kij = 9\n",
        "W = w_int\n",
        "out_int = output_int[batch]\n",
        "out_int = torch.reshape(out_int, (out_int.size(0), -1))\n"
      ],
      "metadata": {
        "id": "M6cYF2LMcaD1"
      },
      "id": "M6cYF2LMcaD1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(W.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx34b6EtsuEY",
        "outputId": "047301fc-42ca-4eb4-a644-bd0034209f5b"
      },
      "id": "tx34b6EtsuEY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 34, 34])\n",
            "torch.Size([64, 3, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = 5\n",
        "in_channels = 3\n",
        "bit_precision = 4\n",
        "h = 3\n",
        "k_size = 3\n",
        "array_size = 8\n",
        "kij = 9\n",
        "\n",
        "for i in range(in_channels):\n",
        "  fname = f\"activation_in_ch{i}.txt\"\n",
        "  file = open(fname, 'w') #write to file\n",
        "  for j in range(h):\n",
        "    for k in range(h):\n",
        "      for l in range(array_size):\n",
        "        #print(round(X[i,j,7-l+k].item()))\n",
        "        X_bin = '{0:04b}'.format(round(X[i,j,7-l+k].item()))\n",
        "        for m in range(bit_precision):\n",
        "              file.write(X_bin[m])\n",
        "      file.write('\\n')\n",
        "\n",
        "  file.close()\n",
        "\n",
        "w_check = []\n",
        "\n",
        "for i in range(in_channels):\n",
        "  fname = f\"weight_in_ch{i}.txt\"\n",
        "  file = open(fname, 'w') #write to file\n",
        "  for ker in range(kij):\n",
        "    for j in range(array_size):\n",
        "      if (7-j == 2):\n",
        "        w_check.append(W[7-j,i,ker].item())\n",
        "        print(f\"o_channel: {7-j}, in_channel {i}, kernel {ker}, value {w_check[-1]}\")\n",
        "      if (round(W[7-j,i,k].item()) >= 0):\n",
        "          W_bin = '{0:04b}'.format(round(W[7-j,i,ker].item()))\n",
        "      else:\n",
        "          W_bin = '{0:04b}'.format(round(W[7-j,i,ker].item())+16)\n",
        "      for k in range(bit_precision):\n",
        "          file.write(W_bin[k])\n",
        "    file.write('\\n')\n",
        "  file.close()\n"
      ],
      "metadata": {
        "id": "oK-LSJ9zcxWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dce6bc6-e426-4c8b-f00c-3477963c1899"
      },
      "id": "oK-LSJ9zcxWZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o_channel: 2, in_channel 0, kernel 0, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 1, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 2, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 3, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 4, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 5, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 6, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 7, value 0.0\n",
            "o_channel: 2, in_channel 0, kernel 8, value 0.0\n",
            "o_channel: 2, in_channel 1, kernel 0, value 0.0\n",
            "o_channel: 2, in_channel 1, kernel 1, value 0.0\n",
            "o_channel: 2, in_channel 1, kernel 2, value 0.0\n",
            "o_channel: 2, in_channel 1, kernel 3, value 0.0\n",
            "o_channel: 2, in_channel 1, kernel 4, value 0.0\n",
            "o_channel: 2, in_channel 1, kernel 5, value 0.0\n",
            "o_channel: 2, in_channel 1, kernel 6, value -0.0\n",
            "o_channel: 2, in_channel 1, kernel 7, value -0.0\n",
            "o_channel: 2, in_channel 1, kernel 8, value -0.0\n",
            "o_channel: 2, in_channel 2, kernel 0, value -0.0\n",
            "o_channel: 2, in_channel 2, kernel 1, value -0.0\n",
            "o_channel: 2, in_channel 2, kernel 2, value -0.0\n",
            "o_channel: 2, in_channel 2, kernel 3, value -7.0\n",
            "o_channel: 2, in_channel 2, kernel 4, value -7.0\n",
            "o_channel: 2, in_channel 2, kernel 5, value -7.0\n",
            "o_channel: 2, in_channel 2, kernel 6, value -7.0\n",
            "o_channel: 2, in_channel 2, kernel 7, value -7.0\n",
            "o_channel: 2, in_channel 2, kernel 8, value -7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_int.shape #out_ch, o_nij"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAHUJoRptHXe",
        "outputId": "aa003b99-df07-4301-99c3-0c60e4e003a0"
      },
      "id": "iAHUJoRptHXe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o_nij = 8\n",
        "o_chan = 8\n",
        "bit_precision = 16\n",
        "\n",
        "fname = \"out.txt\"\n",
        "file = open(fname, 'w') #write to file\n",
        "out_int = relu(out_int) #relu(out_int)\n",
        "for i in range(o_nij):\n",
        "  for o in range(o_chan):\n",
        "    #out_int[7-o,7-i]\n",
        "    if (7-o == 1 and 7-i == 0): print(out_int[7-o,7-i].item())\n",
        "    if (out_int[7-o,7-i].item() >= 0):\n",
        "        Out_bin = '{0:016b}'.format(round(out_int[7-o,7-i].item()))\n",
        "    else:\n",
        "        Out_bin = '{0:016b}'.format(round(out_int[7-o,7-i].item())+65536)\n",
        "    for k in range(bit_precision):\n",
        "        file.write(Out_bin[k])\n",
        "  file.write('\\n')\n",
        "file.close()"
      ],
      "metadata": {
        "id": "4RpoZ4J8s54t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b3a030-3100-4ec0-a93e-d4c0e53b948a"
      },
      "id": "4RpoZ4J8s54t",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out_int[1,1])\n",
        "print(out_int.shape)\n",
        "print(X.shape)\n",
        "print(W.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgKqwA1qBAhp",
        "outputId": "95241bc1-f3c0-4cf0-acd5-5fcc7de7d892"
      },
      "id": "BgKqwA1qBAhp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(56., device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "torch.Size([64, 1024])\n",
            "torch.Size([3, 34, 34])\n",
            "torch.Size([64, 3, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X[:,0:3,1:4]*W[1,:,:].reshape(3,3,3)).sum() #equivalent  to out_ch = 1 and o_ij = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxu6PTdqBHv2",
        "outputId": "97339d70-1f9f-4133-e03f-85aee3c57d34"
      },
      "id": "Qxu6PTdqBHv2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(56., device='cuda:0', grad_fn=<SumBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(profile=\"full\")\n",
        "print(w_check[18:])\n",
        "print(W[2,2,:].reshape(3,3)) #o_ch = 2, in_ch = 2, 0:9\n",
        "weight_int[2,2,:,:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgzNEZf0FZ5L",
        "outputId": "40ee3dfb-c2a0-4c9d-f5be-f6659fec87dd"
      },
      "id": "CgzNEZf0FZ5L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.0, -0.0, -0.0, -7.0, -7.0, -7.0, -7.0, -7.0, -7.0]\n",
            "tensor([[-0., -0., -0.],\n",
            "        [-7., -7., -7.],\n",
            "        [-7., -7., -7.]], device='cuda:0', grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0., -0., -0.],\n",
              "        [-7., -7., -7.],\n",
              "        [-7., -7., -7.]], device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sorted-niger",
      "metadata": {
        "id": "sorted-niger"
      },
      "outputs": [],
      "source": [
        "# # Make sure these match your actual conv layer\n",
        "# stride = 1\n",
        "# padding = 0\n",
        "# dilation = 1\n",
        "# groups = 1\n",
        "# bias = None  # or your bias tensor if you have one\n",
        "\n",
        "# # Convert to float just for comparison\n",
        "# act_f = act_int.to(torch.float32)\n",
        "# weight_f = weight_int.to(torch.float32)\n",
        "\n",
        "# out_check = F.conv2d(\n",
        "#     act_f, weight_f,\n",
        "#     bias=bias,\n",
        "#     stride=stride,\n",
        "#     padding=padding,\n",
        "#     dilation=dilation,\n",
        "#     groups=groups,\n",
        "# )\n",
        "\n",
        "# print(\"F.conv2d value:\", out_check[0, 6, 0, 0].item())\n",
        "# print(\"Your stored output:\", output_int[0, 6, 0, 0].item())\n",
        "\n",
        "# print(output_int.shape) #[128, 64, 32, 32]\n",
        "# print(act_int.shape) #[128, 3, 32, 32]\n",
        "# print(weight_int.shape) #[64, 3, 3, 3]\n",
        "\n",
        "# batch = 0\n",
        "# out_c = 6\n",
        "# h = 0\n",
        "# w = 0\n",
        "\n",
        "# # Extract the relevant input patch (3 input channels, 3x3 window)\n",
        "# # Input shape: [batch, in_channels, H, W]\n",
        "# patch = act_int[batch, :, h:h+3, w:w+3]  # shape [3, 3, 3]\n",
        "\n",
        "# # Extract the kernel for output channel 6\n",
        "# kernel = weight_int[out_c]  # shape [3, 3, 3]\n",
        "\n",
        "# # Elementwise multiply and sum\n",
        "# manual_value = (patch * kernel).sum()\n",
        "\n",
        "# print(\"Manual conv value:\", manual_value)\n",
        "# print(\"Output map value :\", output_int[batch, out_c, h, w])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "significant-whole",
      "metadata": {
        "id": "significant-whole"
      },
      "outputs": [],
      "source": [
        "|\n",
        "\n",
        "# act_int.size = torch.Size([128, 64, 32, 32])  <- batch_size, input_ch, ni, nj\n",
        "a_int = act_int[0,:,:,:]  # pick only one input out of batch\n",
        "# a_int.size() = [64, 32, 32]\n",
        "\n",
        "# conv_int.weight.size() = torch.Size([64, 64, 3, 3])  <- output_ch, input_ch, ki, kj\n",
        "w_int = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))  # merge ki, kj index to kij\n",
        "# w_int.weight.size() = torch.Size([64, 64, 9])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# w_int.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWwkuBIFN6Pm",
        "outputId": "06f7bc37-5a5f-4f84-982f-d0a51b81acbe"
      },
      "id": "DWwkuBIFN6Pm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# padding = 1\n",
        "# stride = 1\n",
        "# array_size = 8 # row and column number\n",
        "\n",
        "# nig = range(a_int.size(1))  ## ni group\n",
        "# njg = range(a_int.size(2))  ## nj group\n",
        "\n",
        "# icg = range(int(w_int.size(1)))  ## input channel\n",
        "# ocg = range(int(w_int.size(0)))  ## output channel\n",
        "\n",
        "# ic_tileg = range(int(len(icg)/array_size))\n",
        "# oc_tileg = range(int(len(ocg)/array_size))\n",
        "\n",
        "# kijg = range(w_int.size(2))\n",
        "# ki_dim = int(math.sqrt(w_int.size(2)))  ## Kernel's 1 dim size\n",
        "\n",
        "# ######## Padding before Convolution #######\n",
        "# a_pad = torch.zeros(len(icg), len(nig)+padding*2, len(nig)+padding*2).cuda()\n",
        "# # a_pad.size() = [64, 32+2pad, 32+2pad]\n",
        "# a_pad[ :, padding:padding+len(nig), padding:padding+len(njg)] = a_int.cuda()\n",
        "# a_pad = torch.reshape(a_pad, (a_pad.size(0), -1))\n",
        "# # a_pad.size() = [64, (32+2pad)*(32+2pad)]\n",
        "\n",
        "\n",
        "# a_tile = torch.zeros(len(ic_tileg), array_size,    a_pad.size(1)).cuda()\n",
        "# w_tile = torch.zeros(len(oc_tileg)*len(ic_tileg), array_size, array_size, len(kijg)).cuda()\n",
        "\n",
        "# for ic_tile in ic_tileg:\n",
        "#     a_tile[ic_tile,:,:] = a_pad[ic_tile*array_size:(ic_tile+1)*array_size,:]\n",
        "\n",
        "# for ic_tile in ic_tileg:\n",
        "#     for oc_tile in oc_tileg:\n",
        "#         w_tile[oc_tile*len(oc_tileg) + ic_tile,:,:,:] = w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, :]\n",
        "\n",
        "\n",
        "\n",
        "# ###########################################\n",
        "\n",
        "# p_nijg = range(a_pad.size(1)) ## psum nij group\n",
        "\n",
        "# psum = torch.zeros(len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)).cuda()\n",
        "\n",
        "# for kij in kijg:\n",
        "#     for ic_tile in ic_tileg:       # Tiling into array_sizeXarray_size array\n",
        "#         for oc_tile in oc_tileg:   # Tiling into array_sizeXarray_size array\n",
        "#             for nij in p_nijg:       # time domain, sequentially given input\n",
        "#                     m = nn.Linear(array_size, array_size, bias=False)\n",
        "#                     m.weight = torch.nn.Parameter(w_int[oc_tile*array_size:(oc_tile+1)*array_size, ic_tile*array_size:(ic_tile+1)*array_size, kij])\n",
        "#                     #m.weight = torch.nn.Parameter(w_tile[len(oc_tileg)*oc_tile+ic_tile,:,:,kij])\n",
        "#                     psum[ic_tile, oc_tile, :, nij, kij] = m(a_tile[ic_tile,:,nij]).cuda()\n"
      ],
      "metadata": {
        "id": "7O3Ic_LpN4Cg"
      },
      "id": "7O3Ic_LpN4Cg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8b4019f-1596-4e25-b840-ebd247e979eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8b4019f-1596-4e25-b840-ebd247e979eb",
        "outputId": "b88a3281-b865-41a3-9bdd-ecf0cc1ef72f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1024])\n",
            "32\n"
          ]
        }
      ],
      "source": [
        "# print(out.shape)\n",
        "# print(o_ni_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "corresponding-significance",
      "metadata": {
        "id": "corresponding-significance"
      },
      "outputs": [],
      "source": [
        "# import math\n",
        "\n",
        "# a_pad_ni_dim = int(math.sqrt(a_pad.size(1))) # 32\n",
        "\n",
        "# o_ni_dim = int((a_pad_ni_dim - (ki_dim- 1) - 1)/stride + 1)\n",
        "# o_nijg = range(o_ni_dim**2)\n",
        "\n",
        "# out = torch.zeros(len(ocg), len(o_nijg)).cuda()\n",
        "\n",
        "\n",
        "# ### SFP accumulation ###\n",
        "# for o_nij in o_nijg:\n",
        "#     for kij in kijg:\n",
        "#         for ic_tile in ic_tileg:\n",
        "#             for oc_tile in oc_tileg:\n",
        "#                 out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] = out[oc_tile*array_size:(oc_tile+1)*array_size, o_nij] + \\\n",
        "#                 psum[ic_tile, oc_tile, :, int(o_nij/o_ni_dim)*a_pad_ni_dim + o_nij%o_ni_dim + int(kij/ki_dim)*a_pad_ni_dim + kij%ki_dim, kij]\n",
        "#                 ## 4th index = (int(o_nij/30)*32 + o_nij%30) + (int(kij/3)*32 + kij%3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exposed-witch",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exposed-witch",
        "outputId": "114c21b5-0d4d-4351-a4c6-2b9ab6de5d39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(440657., device='cuda:0', grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# out_2D = torch.reshape(out, (out.size(0), o_ni_dim, -1))\n",
        "# difference = (out_2D - output_int[:,:,:])\n",
        "# print(difference.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4822876c-eeb6-48d2-851b-aeee3a62b95f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4822876c-eeb6-48d2-851b-aeee3a62b95f",
        "outputId": "ad6dbfa9-85f3-44a6-be9f-1c715df4d0bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# out.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "entitled-barbados",
      "metadata": {
        "id": "entitled-barbados"
      },
      "outputs": [],
      "source": [
        "# ####### Store activation ####################\n",
        "# tile_id = 0\n",
        "# nij = 0 # just a random number\n",
        "# X = a_tile[tile_id,:,:]  # [tile_num, array row num, time_steps]\n",
        "\n",
        "# bit_precision = 4\n",
        "# file = open('activation_tile0.txt', 'w') #write to file\n",
        "# file.write('#time0row7[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
        "# file.write('#time1row7[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
        "# file.write('#................#\\n')\n",
        "\n",
        "# for i in range(X.size(1)):  # time step\n",
        "#     for j in range(X.size(0)): # row #\n",
        "#         X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
        "#         for k in range(bit_precision):\n",
        "#             #print(X_bin[k])\n",
        "#             file.write(X_bin[k])\n",
        "#         #file.write(' ')  # for visibility with blank between words, you can use\n",
        "#     file.write('\\n')\n",
        "# file.close() #close file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "minimal-serbia",
      "metadata": {
        "id": "minimal-serbia",
        "outputId": "682da1b8-1c5f-466a-e882-cec25b74e013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 8, 36])\n",
            "torch.Size([8, 36]) 0\n"
          ]
        }
      ],
      "source": [
        "# print(a_tile.shape)\n",
        "# print(X.shape, nij)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b16851d-8bee-45d1-a172-7f603c971e16",
      "metadata": {
        "id": "3b16851d-8bee-45d1-a172-7f603c971e16"
      },
      "outputs": [],
      "source": [
        "# ####### store weight(kij) ###############\n",
        "# tile_id = 0\n",
        "# kij = 0\n",
        "# bit_precision = 4\n",
        "\n",
        "\n",
        "# for kij in range (9):\n",
        "#     file_name = f'weight_itile0_otile0_kij{kij}.txt'\n",
        "#     W = w_tile[tile_id,:,:,kij] # w_tile[tile_num, array col num, array row num, kij]\n",
        "\n",
        "#     file = open(file_name, 'w')  #write to file\n",
        "#     file.write('#col0row7[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
        "#     file.write('#col1row7[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
        "#     file.write('#................#\\n')\n",
        "\n",
        "#     for i in range(W.size(1)):  # time step\n",
        "#         for j in range(W.size(0)): # row #\n",
        "#             if (W[7-j, i].item() >= 0):\n",
        "#                 W_bin = '{0:04b}'.format(round(W[7-j,i].item()))\n",
        "#             else:\n",
        "#                 W_bin = '{0:04b}'.format(round(W[7-j,i].item())+16)\n",
        "#             for k in range(bit_precision):\n",
        "#                 file.write(W_bin[k])\n",
        "#             #file.write(' ')  # for visibility with blank between words, you can use\n",
        "#         file.write('\\n')\n",
        "#     file.close() #close file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6030ca8-d421-4e77-8bd2-fdc51ed76c15",
      "metadata": {
        "id": "e6030ca8-d421-4e77-8bd2-fdc51ed76c15"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c507518-1e58-411e-b90f-75bdf07c4526",
      "metadata": {
        "id": "1c507518-1e58-411e-b90f-75bdf07c4526"
      },
      "outputs": [],
      "source": [
        "# ### Store psum ###\n",
        "# ic_tile_id = 0\n",
        "# oc_tile_id = 0\n",
        "\n",
        "\n",
        "# kij = 0\n",
        "# nij = 0\n",
        "\n",
        "# # psum[len(ic_tileg), len(oc_tileg), array_size, len(p_nijg), len(kijg)]\n",
        "\n",
        "\n",
        "# bit_precision = 16\n",
        "# file = open('psum.txt', 'w') #write to file\n",
        "# file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
        "# file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
        "# file.write('#................#\\n')\n",
        "\n",
        "# for kij in range(9):\n",
        "#     psum_tile = psum[ic_tile_id,oc_tile_id,:,nij:nij+36,kij]\n",
        "#     for i in range(psum_tile.size(1)):  # time step\n",
        "#         for j in range(psum_tile.size(0)): # row #\n",
        "#             if (psum_tile[7-j, i].item() >= 0):\n",
        "#                 psum_tile_bin = '{0:016b}'.format(round(psum_tile[7-j,i].item()))\n",
        "#             else:\n",
        "#                 psum_tile_bin = '{0:016b}'.format(round(psum_tile[7-j,i].item())+65536)\n",
        "#             #print(W_bin,' ', W[7-j,i].item(), j, i, '\\n')\n",
        "#             for k in range(bit_precision):\n",
        "#                 file.write(psum_tile_bin[k])\n",
        "#             #file.write(' ')  # for visibility with blank between words, you can use\n",
        "#         file.write('\\n')\n",
        "# file.close() #close file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a073597-c0af-4de3-9c41-4d3e710e3e22",
      "metadata": {
        "id": "6a073597-c0af-4de3-9c41-4d3e710e3e22",
        "outputId": "0fa24686-68ff-49b9-e469-c97e02c8e371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000,   98.0000,  154.0000,  168.0000,   84.0000,    0.0000,\n",
            "            0.0000,   77.0000,  147.0000,   91.0000,   49.0000,    0.0000,\n",
            "            0.0000,   98.0000,  147.0000,  -21.0000,  -70.0000,    0.0000,\n",
            "            0.0000,  161.0000,  147.0000,  -14.0000,   -7.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000],\n",
            "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000, -106.0000, -191.0000, -143.0000, -108.0000,    0.0000,\n",
            "            0.0000, -101.0000, -123.0000,  -89.0000,  -49.0000,    0.0000,\n",
            "            0.0000,  -50.0000,  -75.0000,  -25.0000,  -50.0000,    0.0000,\n",
            "            0.0000,  -84.0000,  -85.0000,  -75.0000,  -67.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000],\n",
            "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000, -136.0000, -230.0000, -160.0000, -126.0000,    0.0000,\n",
            "            0.0000, -133.0000, -147.0000,  -91.0000,  -49.0000,    0.0000,\n",
            "            0.0000,  -64.0000,  -99.0000,  -35.0000,  -70.0000,    0.0000,\n",
            "            0.0000, -103.0000, -111.0000, -104.0000,  -91.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000],\n",
            "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000,  112.0000,  224.0000,  154.0000,  126.0000,    0.0000,\n",
            "            0.0000,  133.0000,  147.0000,   91.0000,   49.0000,    0.0000,\n",
            "            0.0000,   28.0000,   63.0000,   35.0000,   70.0000,    0.0000,\n",
            "            0.0000,   49.0000,   63.0000,   98.0000,   91.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000],\n",
            "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000, -126.0000,  -56.0000,   28.0000,    0.0000,    0.0000,\n",
            "            0.0000,  -91.0000,  -21.0000,   77.0000,   49.0000,    0.0000,\n",
            "            0.0000, -112.0000, -147.0000,  -35.0000,  -70.0000,    0.0000,\n",
            "            0.0000, -147.0000, -175.0000, -112.0000,  -77.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000],\n",
            "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000, -126.0000, -238.0000, -168.0000, -126.0000,    0.0000,\n",
            "            0.0000, -133.0000, -147.0000,  -91.0000,  -49.0000,    0.0000,\n",
            "            0.0000, -112.0000, -147.0000,  -35.0000,  -70.0000,    0.0000,\n",
            "            0.0000, -161.0000, -175.0000, -112.0000,  -91.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000],\n",
            "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000,  126.0000,  238.0000,  168.0000,  126.0000,    0.0000,\n",
            "            0.0000,  133.0000,  147.0000,   91.0000,   49.0000,    0.0000,\n",
            "            0.0000,  112.0000,  147.0000,   35.0000,   70.0000,    0.0000,\n",
            "            0.0000,  161.0000,  175.0000,  112.0000,   91.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000],\n",
            "        [   0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000,\n",
            "            0.0000,  -75.0000, -134.0000,  -95.0000,  -69.0000,    0.0000,\n",
            "            0.0000,  -89.0000,  -99.0000,  -42.0000,  -21.0000,    0.0000,\n",
            "            0.0000,  -50.0000,  -84.0000,  -14.0000,  -20.0000,    0.0000,\n",
            "            0.0000,  -73.0000,  -86.0000,  -53.0000,  -47.0000,    0.0000,\n",
            "            0.0000,    0.0000,    0.0000,    0.0000,    0.0000,    0.0000]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
            "tensor([[  392.0000,   161.0000,  -189.0000,  -336.0000,   468.9999,   357.0000,\n",
            "             7.0000,   -63.0000,   510.9999,   231.0000,  -119.0000,   -28.0000,\n",
            "           329.0000,    70.0000,  -294.0000,   -42.0000],\n",
            "        [ -579.0000,  -907.0000,  -777.0000,  -428.0000,  -777.0000, -1188.0000,\n",
            "         -1036.0000,  -539.0000,  -718.0000, -1027.0000,  -819.9999,  -448.0000,\n",
            "          -431.0000,  -620.0000,  -535.0000,  -303.0000],\n",
            "        [ -681.9999,  -941.0000,  -819.0000,  -434.0000,  -878.9999, -1187.0000,\n",
            "         -1058.0000,  -538.0000,  -773.9999, -1075.9999,  -897.9999,  -446.0000,\n",
            "          -576.9999,  -745.9999,  -624.0000,  -308.0000],\n",
            "        [  518.0000,   819.0000,   791.0000,   420.0000,   538.9999,   720.9999,\n",
            "           496.9999,    -7.0000,   245.0000,   469.0000,   385.0000,    84.0000,\n",
            "           147.0000,   196.0000,   490.0000,   294.0000],\n",
            "        [  280.0000,   371.0000,     7.0000,  -238.0000,   -21.0000,   273.0000,\n",
            "           175.0000,    63.0000,  -259.0000,   105.0000,   370.9999,   252.0000,\n",
            "          -217.0000,  -140.0000,    84.0000,   154.0000],\n",
            "        [  -42.0000,   -49.0000,    91.0000,   238.0000,     7.0000,   -91.0000,\n",
            "          -469.0000,  -259.0000,   245.0000,    -7.0000,  -482.9999,  -350.0000,\n",
            "           231.0000,   252.0000,  -154.0000,  -154.0000],\n",
            "        [  461.9999,   511.0000,   371.0000,    84.0000,   427.0000,   622.9999,\n",
            "           343.0000,   -91.0000,   454.9999,   538.9999,   245.0000,  -126.0000,\n",
            "           385.0000,   475.9999,   224.0000,    70.0000],\n",
            "        [ -611.0000,  -684.0000,  -559.0000,  -294.0000,  -851.9999,  -895.0000,\n",
            "          -672.0000,  -443.0000,  -724.0000,  -738.9999,  -478.0000,  -327.0000,\n",
            "          -461.0000,  -529.0000,  -404.0000,  -195.0000]], device='cuda:0',\n",
            "       grad_fn=<CopySlices>)\n"
          ]
        }
      ],
      "source": [
        "# psum_tile.shape\n",
        "# print(psum_tile)\n",
        "# print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639ce918-1a60-4a94-bb4e-fe2b4cd80477",
      "metadata": {
        "id": "639ce918-1a60-4a94-bb4e-fe2b4cd80477",
        "outputId": "fd3e772c-18c3-4bd2-a332-ded6cd6a037f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[392.0000, 161.0000,   0.0000,   0.0000, 468.9999, 357.0000,   7.0000,\n",
            "           0.0000, 510.9999, 231.0000,   0.0000,   0.0000, 329.0000,  70.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [518.0000, 819.0000, 791.0000, 420.0000, 538.9999, 720.9999, 496.9999,\n",
            "           0.0000, 245.0000, 469.0000, 385.0000,  84.0000, 147.0000, 196.0000,\n",
            "         490.0000, 294.0000],\n",
            "        [280.0000, 371.0000,   7.0000,   0.0000,   0.0000, 273.0000, 175.0000,\n",
            "          63.0000,   0.0000, 105.0000, 370.9999, 252.0000,   0.0000,   0.0000,\n",
            "          84.0000, 154.0000],\n",
            "        [  0.0000,   0.0000,  91.0000, 238.0000,   7.0000,   0.0000,   0.0000,\n",
            "           0.0000, 245.0000,   0.0000,   0.0000,   0.0000, 231.0000, 252.0000,\n",
            "           0.0000,   0.0000],\n",
            "        [461.9999, 511.0000, 371.0000,  84.0000, 427.0000, 622.9999, 343.0000,\n",
            "           0.0000, 454.9999, 538.9999, 245.0000,   0.0000, 385.0000, 475.9999,\n",
            "         224.0000,  70.0000],\n",
            "        [  0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "           0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
            "           0.0000,   0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# bit_precision = 16\n",
        "# file = open('out.txt', 'w') #write to file\n",
        "# file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
        "# file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
        "# file.write('#................#\\n')\n",
        "\n",
        "# out_relu = relu(out)\n",
        "# print(out_relu)\n",
        "# for i in range(out_relu.size(1)):  # time step\n",
        "#     for j in range(out_relu.size(0)): # row #\n",
        "#         #Out_bin = '{0:016b}'.format(round(out[7-j,i].item()))\n",
        "#         if (out[7-j, i].item() >= 0):\n",
        "#             Out_bin = '{0:016b}'.format(round(out_relu[7-j,i].item()))\n",
        "#         else:\n",
        "#             Out_bin = '{0:016b}'.format(round(out_relu[7-j,i].item())+65536)\n",
        "#         for k in range(bit_precision):\n",
        "#             #print(X_bin[k])\n",
        "#             file.write(Out_bin[k])\n",
        "#        #file.write(' ')  # for visibility with blank between words, you can use\n",
        "#     file.write('\\n')\n",
        "# file.close() #close file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff22a99-404f-4adc-92b7-92999ace93fb",
      "metadata": {
        "id": "cff22a99-404f-4adc-92b7-92999ace93fb",
        "outputId": "fb7d7661-110d-4149-c3ca-20bdec86cdb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The last column in out.txt is\n",
            "\n",
            "['0000000110001000', '0000000010100001', '1000000000000000', '1000000000000000', '0000000111010101', '0000000101100101', '0000000000000111', '1000000000000000', '0000000111111111', '0000000011100111', '1000000000000000', '1000000000000000', '0000000101001001', '0000000001000110', '1000000000000000', '1000000000000000']\n",
            "\n",
            "Convert binary number into decimal number\n",
            "\n",
            "[392, 161, -32768, -32768, 469, 357, 7, -32768, 511, 231, -32768, -32768, 329, 70, -32768, -32768]\n"
          ]
        }
      ],
      "source": [
        "# ##### The following code is just for verification #####\n",
        "# ##### Please Ignore #####\n",
        "# file = open('out.txt', 'r')\n",
        "# result = []\n",
        "\n",
        "# # Obtain the value in the last column\n",
        "# for line in file:\n",
        "#     line = line.strip()\n",
        "#     if not line or line.startswith(\"#\"):\n",
        "#         continue\n",
        "#     parts = line.split()\n",
        "#     last_col = parts[-1]\n",
        "#     result.append(last_col)\n",
        "\n",
        "# print('The last column in out.txt is\\n')\n",
        "# print(result)\n",
        "\n",
        "# def twos_complement_to_int(num_str, bits=16):\n",
        "#     num_str = num_str.zfill(bits)\n",
        "#     num = int(num_str, 2)\n",
        "#     if num >= 2**(bits-1):\n",
        "#         num -= 2**bits\n",
        "#     return num\n",
        "\n",
        "# print('\\nConvert binary number into decimal number\\n')\n",
        "# result_int = [twos_complement_to_int(x) for x in result]\n",
        "# print(result_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e48ee0-9e54-4cfa-aa9e-17c8c20e97f0",
      "metadata": {
        "id": "d7e48ee0-9e54-4cfa-aa9e-17c8c20e97f0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c88249-b031-444b-b5a9-fe30e0c191ce",
      "metadata": {
        "id": "28c88249-b031-444b-b5a9-fe30e0c191ce"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcfc0fdc-a3b7-4c13-b7cf-80c92e3515ff",
      "metadata": {
        "id": "bcfc0fdc-a3b7-4c13-b7cf-80c92e3515ff"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}